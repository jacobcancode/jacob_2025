{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Computing Bias\n",
    "permalink: /posts/computingbias/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popcorn Hack #1:\n",
    "Example: Google Translate shows gender bias by translating neutral phrases with stereotypical gender roles.\n",
    "Cause: Trained on biased data reflecting societal norms.\n",
    "\n",
    "Popcorn Hack #2:\n",
    "Experience: A voice-to-text app struggled with my accent, making me feel excluded.\n",
    "Fix: Train with diverse accents or allow accent adjustments.\n",
    "\n",
    "Popcorn Hack #3:\n",
    "Bias in Fitness App: Assumes all users have the same abilities, ignoring diverse needs.\n",
    "Fix: Add customizable goals, adaptive algorithms, and test with diverse groups.\n",
    "\n",
    "Homework Hack:\n",
    "Tool: Amazon\n",
    "Bias: Amazon’s recommendations often show similar products based on past purchases, limiting exposure to new categories.\n",
    "Cause: The recommendation engine focuses too much on previous behavior, reinforcing a “filter bubble.”\n",
    "Fix: Add an “Explore New Categories” option to suggest diverse products or emerging brands. This could help users discover items they wouldn’t normally see and make the platform more inclusive.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
